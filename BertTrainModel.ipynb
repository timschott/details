{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BertTrainModel.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sDh-kfcnxKPI"},"source":["Thie notebook explores using BERT for text classification.  Before starting, change the runtime to GPU: Runtime > Change runtime type > Hardware accelerator: GPU."]},{"cell_type":"markdown","metadata":{"id":"3m2nlYY_dnXP"},"source":["Give this notebook access to the data in your ANLP21 folder so we can train and evaluate BERT on the `details` data.  (Note you are only providing this access to yourself as you execute this notebook.)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4nx0eL5cuTd","executionInfo":{"status":"ok","timestamp":1638144750258,"user_tz":480,"elapsed":14680,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}},"outputId":"99a6856d-2cf9-4971-b824-1d3aed505062"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"kRyQBPDKxczl"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWZy26Ld0nGo","executionInfo":{"status":"ok","timestamp":1638144773144,"user_tz":480,"elapsed":7764,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["from transformers import BertModel, BertTokenizer\n","import torch\n","from tqdm import tqdm\n","import torch.nn as nn\n","import numpy as np\n","import random\n","import time"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g_N5SRVPyvDt"},"source":["Double-check that this notebook is running on the GPU (this should \"Running on cuda\")."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTsJHWfVzS6Y","executionInfo":{"status":"ok","timestamp":1638144775774,"user_tz":480,"elapsed":140,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}},"outputId":"6432052b-1d96-47b1-f4fd-cf9d1a5d8bbd"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Running on {}\".format(device))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on cuda\n"]}]},{"cell_type":"code","metadata":{"id":"iH5KcMBMxKPP","executionInfo":{"status":"ok","timestamp":1638144783193,"user_tz":480,"elapsed":131,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["def read_labels(filename):\n","    labels={}\n","    with open(filename) as file:\n","        for line in file:\n","            cols = line.split(\"\\t\")\n","            label = cols[0]\n","            if label not in labels:\n","                labels[label]=len(labels)\n","    return labels"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUOIgxLrxKPQ","executionInfo":{"status":"ok","timestamp":1638144784945,"user_tz":480,"elapsed":139,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["def read_data(filename, labels, max_data_points=None):\n","    \"\"\"\n","    :param filename: the name of the file\n","    :return: list of tuple ([word index list], label)\n","    as input for the forward and backward function\n","    \"\"\"    \n","    data = []\n","    data_labels = []\n","    with open(filename) as file:\n","        for line in file:\n","            cols = line.split(\"\\t\")\n","            label = cols[0]\n","            text = cols[1]\n","            \n","            data.append(text)\n","            data_labels.append(labels[label])\n","            \n","\n","    # shuffle the data\n","    tmp = list(zip(data, data_labels))\n","    random.shuffle(tmp)\n","    data, data_labels = zip(*tmp)\n","    \n","    if max_data_points is None:\n","        return data, data_labels\n","    \n","    return data[:max_data_points], data_labels[:max_data_points]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSMOvzrNxKPS","executionInfo":{"status":"ok","timestamp":1638144787692,"user_tz":480,"elapsed":496,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}},"outputId":"9da54d8a-c1f0-4897-f822-2cecddc7a102"},"source":["labels=read_labels(\"/content/drive/MyDrive/ANLP21/details/train.tsv\")\n","print(labels)\n","assert len(labels) == 2"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'detail': 0, 'not_detail': 1}\n"]}]},{"cell_type":"code","metadata":{"id":"JmHGHDJDxKPS","executionInfo":{"status":"ok","timestamp":1638144957894,"user_tz":480,"elapsed":143,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["train_x, train_y=read_data(\"/content/drive/MyDrive/ANLP21/details/train.tsv\", labels)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lri3K6TsxKPT","executionInfo":{"status":"ok","timestamp":1638144959695,"user_tz":480,"elapsed":174,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["dev_x, dev_y=read_data(\"/content/drive/MyDrive/ANLP21/details/dev.tsv\", labels)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"0aMsvhvkxKPT","executionInfo":{"status":"ok","timestamp":1638144794004,"user_tz":480,"elapsed":135,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["def evaluate(model, x, y):\n","    model.eval()\n","    corr = 0.\n","    total = 0.\n","    with torch.no_grad():\n","        for x, y in zip(x, y):\n","            y_preds=model.forward(x)\n","            for idx, y_pred in enumerate(y_preds):\n","                prediction=torch.argmax(y_pred)\n","                if prediction == y[idx]:\n","                    corr += 1.\n","                total+=1                          \n","    return corr/total"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyE_hJzpxKPU","executionInfo":{"status":"ok","timestamp":1638144796085,"user_tz":480,"elapsed":145,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["class BERTClassifier(nn.Module):\n","\n","    \n","    def __init__(self, params):\n","        super().__init__()\n","    \n","        self.model_name=params[\"model_name\"]\n","        self.tokenizer = BertTokenizer.from_pretrained(self.model_name, do_lower_case=params[\"doLowerCase\"], do_basic_tokenize=False)\n","        self.bert = BertModel.from_pretrained(self.model_name)\n","        \n","        self.num_labels = params[\"label_length\"]\n","\n","        self.fc = nn.Linear(params[\"embedding_size\"], self.num_labels)\n","\n","    def get_batches(self, all_x, all_y, batch_size=32, max_toks=512):\n","            \n","        \"\"\" Get batches for input x, y data, with data tokenized according to the BERT tokenizer \n","      (and limited to a maximum number of WordPiece tokens \"\"\"\n","\n","        batches_x=[]\n","        batches_y=[]\n","        \n","        for i in range(0, len(all_x), batch_size):\n","\n","            current_batch=[]\n","\n","            x=all_x[i:i+batch_size]\n","\n","            batch_x = self.tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_toks)\n","            batch_y=all_y[i:i+batch_size]\n","\n","            batches_x.append(batch_x.to(device))\n","            batches_y.append(torch.LongTensor(batch_y).to(device))\n","            \n","        return batches_x, batches_y\n","  \n","\n","    def forward(self, batch_x): \n","    \n","        bert_output = self.bert(input_ids=batch_x[\"input_ids\"],\n","                         attention_mask=batch_x[\"attention_mask\"],\n","                         token_type_ids=batch_x[\"token_type_ids\"],\n","                         output_hidden_states=True)\n","\n","        bert_hidden_states = bert_output['hidden_states']\n","\n","        # We're going to represent an entire document just by its [CLS] embedding (at position 0)\n","        out = bert_hidden_states[-1][:,0,:]\n","\n","        out = self.fc(out)\n","\n","        return out.squeeze()"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EC3ysAoFfX4n"},"source":["Now let's train BERT on this data.  A few practicalities of this environment: if you encounter an out of memory error:\n","\n","* Reset the notebook (Runtime > Factory reset runtime) and execute all cells from the beginning.\n","* If your `max_length` is high, try reducing the `batch_size` in `get_batches` above.\n","\n","Even on a GPU, BERT can take a long time to train, so you might try experimenting first with smaller `max_data_points` above. before running it on the full training data."]},{"cell_type":"code","metadata":{"id":"WZtoU7jzxKPU","executionInfo":{"status":"ok","timestamp":1638144801693,"user_tz":480,"elapsed":153,"user":{"displayName":"Timothy Schott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuSKxyOW8sKdqkmCkfIDBUsZ1mtFtZHt3CUwLpbQ=s64","userId":"02666320297537601305"}}},"source":["def train_and_evaluate(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=768, doLowerCase=None):\n","\n","  start_time=time.time()\n","  bert_model = BERTClassifier(params={\"doLowerCase\": doLowerCase, \"model_name\": bert_model_name, \"embedding_size\":embedding_size, \"label_length\": len(labels)})\n","  bert_model.to(device)\n","\n","  batch_x, batch_y = bert_model.get_batches(train_x, train_y)\n","  dev_batch_x, dev_batch_y = bert_model.get_batches(dev_x, dev_y)\n","\n","  optimizer = torch.optim.Adam(bert_model.parameters(), lr=1e-5)\n","  cross_entropy=nn.CrossEntropyLoss()\n","\n","  num_epochs=5\n","  best_dev_acc = 0.\n","\n","  for epoch in range(num_epochs):\n","      bert_model.train()\n","\n","      # Train\n","      for x, y in tqdm(list(zip(batch_x, batch_y))):\n","          y_pred = bert_model.forward(x)\n","          loss = cross_entropy(y_pred.view(-1, bert_model.num_labels), y.view(-1))\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","      \n","      # Evaluate\n","      dev_accuracy=evaluate(bert_model, dev_batch_x, dev_batch_y)\n","      if epoch % 1 == 0:\n","          print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n","          if dev_accuracy > best_dev_acc:\n","              torch.save(bert_model.state_dict(), model_filename)\n","              best_dev_acc = dev_accuracy\n","\n","  bert_model.load_state_dict(torch.load(model_filename))\n","  torch.save(bert_model.state_dict(), \"/content/drive/MyDrive/ANLP21/details/models/\" + model_filename + \".pt\")\n","  print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))\n","  print(\"Time: %.3f seconds ---\" % (time.time() - start_time))"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmzpNl5fbNgz"},"source":["#### BERT TINY\n","https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-128_A-2.zip\n","\n","Best Accuracy: .486\n","Time - ~ 17 seconds"]},{"cell_type":"code","metadata":{"id":"c1xQgyJs56En"},"source":["train_and_evaluate(\"google/bert_uncased_L-2_H-128_A-2\", \"lmrd-uncased_L-2_H-128_A-2\", train_x, train_y, dev_x, dev_y, labels, embedding_size=128, doLowerCase=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KEN25DB1vSYe"},"source":["#### BERT MINI\n","https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-256_A-4.zip\n","\n","Best Accuracy: .714\n","Training Time: ~ 6"]},{"cell_type":"code","metadata":{"id":"RM03zM5Fu-iz"},"source":["train_and_evaluate(\"google/bert_uncased_L-4_H-256_A-4\", \"details-uncased_L-4_H-256_A-4\", train_x, train_y, dev_x, dev_y, labels, embedding_size=256, doLowerCase=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kgYbS1-wxXQ4"},"source":["#### BERT Small\n","https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-512_A-8.zip\n","\n","Best accuracy: .714\n","Training Time: ~ 9 seconds"]},{"cell_type":"code","metadata":{"id":"rJUeXw98xXxQ"},"source":["train_and_evaluate(\"google/bert_uncased_L-4_H-512_A-8\", \"details-uncased_L-4_H-512_A-8\", train_x, train_y, dev_x, dev_y, labels, embedding_size=512, doLowerCase=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1iy63xGbzy8M"},"source":["#### BERT Medium\n","https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-8_H-512_A-8.zip\n","\n","Best Accuracy: .800\n","Training Time: ~45"]},{"cell_type":"code","metadata":{"id":"Ss4Qav3gz0Og"},"source":["train_and_evaluate(\"google/bert_uncased_L-8_H-512_A-8\", \"details-uncased_L-8_H-512_A-8\", train_x, train_y, dev_x, dev_y, labels, embedding_size=512, doLowerCase=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9vcZkWxbjbn"},"source":["#### BERT BASE\n","\n","Best accuracy, .657\n","Traning time, ~52 seconds"]},{"cell_type":"code","metadata":{"id":"CgLvw1VRiqR_"},"source":["train_and_evaluate(\"bert-base-cased\", \"details-bert-base-cased\", train_x, train_y, dev_x, dev_y, labels, embedding_size=768, doLowerCase=False)"],"execution_count":null,"outputs":[]}]}