{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e247c989",
   "metadata": {},
   "source": [
    "# RELiC Dataset Analysis\n",
    "\n",
    "* setup\n",
    "\n",
    "## Analyze Descriptive Passages\n",
    "\n",
    "* content\n",
    "* time series\n",
    "* topic modeling\n",
    "* neural\n",
    "\n",
    "## Analyze Critical Claims\n",
    "\n",
    "* broad analysis\n",
    "* more grounded coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e7c71",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7a431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# POS\n",
    "import spacy\n",
    "\n",
    "# nltk for wordnet and tokenization\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus.reader.wordnet import WordNetError\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc42eeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7fb44039eb20>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy parser\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "nlp.remove_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e60b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read in .csv of descriptive passages as a Pandas data frame\n",
    "Add appropriate header to the columns as well.\n",
    "col names are: \n",
    "[blank],passage,book,left_claim,left_claim_keywords,\n",
    "right_claim,right_claim_keywords,claim_id,passage_id,\n",
    "passage_size,match_output\n",
    "\n",
    "'''\n",
    "def read_as_df(filename):\n",
    "    # read data\n",
    "    df = pd.read_csv(filename)\n",
    "    # filter out first column as well as books that are not Left/Both\n",
    "    df = df[df['match_output'] != 'Right']\n",
    "    # drop unneeded row number\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0062b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper for reporting 5-number summary of an inputted list\n",
    "'''\n",
    "def five_number(data):\n",
    "    # calculate quartiles\n",
    "    quartiles = np.percentile(data, [25, 50, 75])\n",
    "    # calculate min/max\n",
    "    data_min, data_max = data.min(), data.max()\n",
    "    # print 5-number summary\n",
    "    print('Min: %.3f' % data_min)\n",
    "    print('Q1: %.3f' % quartiles[0])\n",
    "    print('Median: %.3f' % quartiles[1])\n",
    "    print('Q3: %.3f' % quartiles[2])\n",
    "    print('Max: %.3f' % data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40aab4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_df = read_as_df('data/descriptive_claims_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a970d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2383, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6d00f",
   "metadata": {},
   "source": [
    "### Analyze Descriptive Passages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39acd2d",
   "metadata": {},
   "source": [
    "### content work\n",
    "\n",
    "* spaCy on each description\n",
    "    * general counts of adj, prep, pronoun, and can be used for later analysis\n",
    "* column view Ã  la Bal, Tenen\n",
    "    * words per unique thing (Tenen) -- in just these descriptive passages; aka Unique Clutter Distance\n",
    "    * words per thing (Tenen) -- in just these descriptive passages (self-selecting sample); aka Clutter Distance\n",
    "* specificity (Nelson 2020)\n",
    "    * per descriptive passage, calculate specificity rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af438a",
   "metadata": {},
   "source": [
    "#### Column View (Bal, Tenen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93914577",
   "metadata": {},
   "source": [
    "#### Specificity (Nelson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c5f3b",
   "metadata": {},
   "source": [
    "### time series\n",
    "\n",
    "would need:\n",
    "* number of fragments total\n",
    "* number of descriptive fragments\n",
    "* publish years for each work\n",
    "* -> pessimstic view of descriptive passages/work/time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c77850",
   "metadata": {},
   "source": [
    "### topic model\n",
    "\n",
    "* what is each description/claim talking about"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea20361",
   "metadata": {},
   "source": [
    "### neural\n",
    "* universal sentence encoder, across each description, and then cluster together?\n",
    "* looking for different authors creating similar descriptions ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090806d8",
   "metadata": {},
   "source": [
    "### analyze critical claims\n",
    "\n",
    "* number of subjects\n",
    "* entities\n",
    "* repeats?\n",
    "* mentioning other criticisms?\n",
    "* more grounded-coding -- who is close-reading, what else fits, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699d2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa89c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
