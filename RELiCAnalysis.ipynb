{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88f1cf8",
   "metadata": {},
   "source": [
    "## Analyze Descriptive Passages\n",
    "\n",
    "* setup\n",
    "* content\n",
    "* parts of speech based\n",
    "* time series\n",
    "* topic modeling\n",
    "* neural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d71ab7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d3148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6bda399",
   "metadata": {},
   "source": [
    "### content work\n",
    "* descriptive words / total words (quite pessimistic)\n",
    "* words per unique thing (Tenen) -- in just these descriptive passages; aka Unique Clutter Distance\n",
    "* words per thing (Tenen) -- in just these descriptive passages (self-selecting sample); aka Clutter Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8c872",
   "metadata": {},
   "source": [
    "### Parts of Speech Based Analysis\n",
    "\n",
    "* spaCy on each description\n",
    "* column view a la Bal, Tenen\n",
    "* specificity (Nelson 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9b4f3",
   "metadata": {},
   "source": [
    "#### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner,parser'])\n",
    "nlp.remove_pipe('ner')\n",
    "nlp.remove_pipe('parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function from http://www.nltk.org/howto/wordnet.html to get *all* of a synset's hyponym/hypernyms\n",
    "hyper = lambda s: s.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c08c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Consult wordnet for the situation of a noun and verb with respect to its station in the hypernym hierarchy. \n",
    "Based on current SOA, it is acceptable to simply grab the top-level (.01) synset.\n",
    "\n",
    "Args:\n",
    "    tagged_sample: a spacy doc\n",
    "\n",
    "Return:\n",
    "    specificity: a value conveying the \"specificity\" of the input, via Nelson (2020)\n",
    "'''\n",
    "\n",
    "def specificity(sample):\n",
    "    tagged_sample=nlp(sample)\n",
    "    hyper_sum = 0\n",
    "    noun_and_verb_count = 0\n",
    "    for word in tagged_sample:\n",
    "        if not wn.synsets(word.lemma_):\n",
    "            continue\n",
    "        else:\n",
    "            if word.pos_ == \"NOUN\" or word.pos_ == \"VERB\":\n",
    "                noun_and_verb_count +=1\n",
    "                # if it's a verb, get the most common verb hypernym chain\n",
    "                # else, get the most common noun hypernym chain\n",
    "                pos = word.pos_\n",
    "                tag = \"n\" if pos.startswith(\"N\") else \"v\"\n",
    "                synset = word.lemma_ + \".\" + tag + \".01\"\n",
    "                hyper_sum += len(list(wn.synset(synset).closure(hyper)))\n",
    "    \n",
    "    return hyper_sum / noun_and_verb_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f2f85",
   "metadata": {},
   "source": [
    "### time series\n",
    "\n",
    "would need:\n",
    "* number of fragments total\n",
    "* number of descriptive fragments\n",
    "* publish years for each work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a59a05",
   "metadata": {},
   "source": [
    "### topic model\n",
    "\n",
    "* what is each description/claim talking about"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6e6f2",
   "metadata": {},
   "source": [
    "### embeddings.. \n",
    "* universal sentence encoder, across each description, and then cluster together?\n",
    "* looking for different authors creating similar descriptions ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
