{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "df9aa7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter\n",
    "from collections import Counter\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# POS\n",
    "import spacy\n",
    "\n",
    "# sorting dicts\n",
    "import operator\n",
    "\n",
    "# chi squared\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import fisher_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbecd329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x136fdbd60>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner,parser'])\n",
    "nlp.remove_pipe('ner')\n",
    "nlp.remove_pipe('parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1f567b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read in .tsv of tagged sample data as a Pandas data frame\n",
    "Add appropriate header to the columns as well.\n",
    "'''\n",
    "def read_as_df(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename, sep=\"\\t\", header = None)\n",
    "    df.columns = [\"Text_Loc\", \"Sample\", \"Rating\", \"Specificity\",\"Adj\", \"Adv\", \"Noun\", \"Verb\", \"Adp\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "855dde27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identifies frequencies for preposition usage across the samples.\n",
    "Provides output in the form suitable for chi-square analysis.\n",
    "'''\n",
    "def prep_capture(samples, detail_rating):\n",
    "    preps = set()\n",
    "    details_counter = Counter()\n",
    "    not_details_counter = Counter()\n",
    "    total_words = 0\n",
    "    detail_word_count = 0\n",
    "    not_detail_word_count = 0\n",
    "    for index, value in enumerate(samples):\n",
    "        score = detail_rating[index]\n",
    "        sample = nlp(samples[index])\n",
    "        for word in sample:\n",
    "            if word.pos_ != 'PUNC':\n",
    "                total_words += 1\n",
    "                if score >= 3.0:\n",
    "                    detail_word_count += 1\n",
    "                else:\n",
    "                    not_detail_word_count += 1\n",
    "            if word.pos_ == 'ADP':\n",
    "                if score >= 3.0:\n",
    "                    if word.text not in details_counter:\n",
    "                        details_counter[word.text] = 1\n",
    "                    else:\n",
    "                        details_counter[word.text] += 1\n",
    "                    \n",
    "                else:\n",
    "                    if word.text not in not_details_counter:\n",
    "                        not_details_counter[word.text] = 1\n",
    "                    else:\n",
    "                        not_details_counter[word.text] += 1\n",
    "    \n",
    "    # first, remove anything that has an observed count of < 5 -- probably some weird typo.\n",
    "    \n",
    "    details_counter = {k: v for k, v in details_counter.items() if v >= 5}\n",
    "    not_details_counter = {k: v for k, v in not_details_counter.items() if v >= 5}\n",
    "    \n",
    "    # now, double check that details_counter and not_details_counter both have same elements\n",
    "    # if they aren't, add the missing entries and give them a count of 0\n",
    "    \n",
    "    for key in details_counter.keys():\n",
    "        if key not in not_details_counter.keys():\n",
    "            not_details_counter[key] = 0\n",
    "    for key in not_details_counter.keys():\n",
    "        if key not in details_counter.keys():\n",
    "            details_counter[key] = 0\n",
    "            \n",
    "    # sort them, by their keys, so we can easily iterate + compare.\n",
    "    sorted_detail_counts = dict(sorted(details_counter.items(), key=operator.itemgetter(0), reverse = False))\n",
    "    sorted_not_detail_counts = dict(sorted(not_details_counter.items(), key=operator.itemgetter(0), reverse = False))\n",
    "\n",
    "    return sorted_detail_counts, sorted_not_detail_counts, total_words, detail_word_count, not_detail_word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9f267bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_test(detail_counts, not_detail_counts, total_word_count, detail_word_count, not_detail_word_count):\n",
    "    \n",
    "    for word, count in detail_counts.items():\n",
    "        # top left\n",
    "        word_of_interest_detail_count = detail_counts[word]\n",
    "        # bottom left\n",
    "        word_of_interest_not_detail_count = not_detail_counts[word]\n",
    "        \n",
    "        # top right\n",
    "        detail_leftover = detail_word_count - word_of_interest_detail_count\n",
    "        # bottom right\n",
    "        not_detail_leftover = not_detail_word_count - word_of_interest_not_detail_count\n",
    "        \n",
    "        # now, transform each of these \"cells\" into the frequencies expected by chi squared.\n",
    "        table = [[word_of_interest_detail_count, detail_leftover],\n",
    "                [word_of_interest_not_detail_count, not_detail_leftover]]\n",
    "        \n",
    "        # run chi square\n",
    "        stat, p, dof, expected = chi2_contingency(table)\n",
    "        \n",
    "        fisher = False\n",
    "        for row in expected:\n",
    "            for i in row:\n",
    "                if i < 5.0:\n",
    "                    stat, p = fisher_exact(table)\n",
    "                    fisher = True\n",
    "                    \n",
    "        reject = 'REJECT' if p < .05 else 'ACCEPT'\n",
    "        \n",
    "        print(f'{word}, {stat}, {p}, {reject}, {fisher}')\n",
    "        \n",
    "        # make sure expected for the table is over 5, or else re-run w/ fisher's exact test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "89c2d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_as_df(\"data/samples_data.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "99d59ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Loc</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Adj</th>\n",
       "      <th>Adv</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Adp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Gutenberg/samples/heart_of_darkness_20960_2...</td>\n",
       "      <td>...lap. she wore a starched white affair on he...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Gutenberg/samples/adam_bede_601425_602225.txt</td>\n",
       "      <td>...him, if he had known it, that the general a...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.758621</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Gutenberg/samples/middlemarch_1718514_17193...</td>\n",
       "      <td>...passionate exclamation, as if some torture ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.945455</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Gutenberg/samples/tom_jones_1740540_1741340...</td>\n",
       "      <td>...so vicious a passion from your heart, and y...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.823529</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Gutenberg/samples/the_jungle_691598_692398.txt</td>\n",
       "      <td>...intensity, staring at the platform as if no...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.407407</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Text_Loc  \\\n",
       "0  ../Gutenberg/samples/heart_of_darkness_20960_2...   \n",
       "1   ../Gutenberg/samples/adam_bede_601425_602225.txt   \n",
       "2  ../Gutenberg/samples/middlemarch_1718514_17193...   \n",
       "3  ../Gutenberg/samples/tom_jones_1740540_1741340...   \n",
       "4  ../Gutenberg/samples/the_jungle_691598_692398.txt   \n",
       "\n",
       "                                              Sample  Rating  Specificity  \\\n",
       "0  ...lap. she wore a starched white affair on he...     4.5     4.565217   \n",
       "1  ...him, if he had known it, that the general a...     2.5     4.758621   \n",
       "2  ...passionate exclamation, as if some torture ...     2.0     2.945455   \n",
       "3  ...so vicious a passion from your heart, and y...     1.5     4.823529   \n",
       "4  ...intensity, staring at the platform as if no...     2.0     3.407407   \n",
       "\n",
       "   Adj  Adv  Noun  Verb  Adp  \n",
       "0   20    7    29    21   21  \n",
       "1   16   10    36    24   20  \n",
       "2    9    8    21    35   20  \n",
       "3   10   10    29    29   16  \n",
       "4   12   13    22    33    9  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "84742d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_preps, not_detail_preps, total_word_count, detail_word_count, not_detail_word_count = prep_capture(df['Sample'], df['Rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "529e8c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "not_detail_word_count + detail_word_count == total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d173f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about, 0.9577494866310962, 0.3277545450719886, ACCEPT, False\n",
      "above, 8.448165359911389, 0.003654118757087796, REJECT, False\n",
      "across, inf, 0.013785158741037891, REJECT, True\n",
      "after, 0.009158609719237133, 0.9237583441122709, ACCEPT, False\n",
      "against, 0.0025153793545150335, 0.9600000204953151, ACCEPT, False\n",
      "along, 8.448165359911389, 0.003654118757087796, REJECT, False\n",
      "among, 0.43011242816266726, 0.511933786618215, ACCEPT, False\n",
      "around, inf, 0.02521392390885113, REJECT, True\n",
      "as, 0.005672810396611961, 0.9399616512549686, ACCEPT, False\n",
      "at, 7.907850012440252, 0.004922073325194035, REJECT, False\n",
      "before, 0.929403903766011, 0.3350178682249272, ACCEPT, False\n",
      "behind, inf, 0.002455012450743315, REJECT, True\n",
      "beside, inf, 0.04675106132229724, REJECT, True\n",
      "between, 0.5391678904029764, 0.46277778434594863, ACCEPT, False\n",
      "beyond, inf, 0.02521392390885113, REJECT, True\n",
      "by, 2.344921603594894, 0.12569188480936394, ACCEPT, False\n",
      "down, 9.943001992395448, 0.0016146202205057452, REJECT, False\n",
      "during, 0.30475829269749694, 0.5809146616780605, ACCEPT, False\n",
      "for, 8.91704035231372, 0.002825219915804036, REJECT, False\n",
      "from, 0.5124894062810413, 0.47406319236849215, ACCEPT, False\n",
      "in, 6.20655288805506, 0.012727824092617242, REJECT, False\n",
      "into, 7.442944300539575, 0.006368561824842411, REJECT, False\n",
      "like, 0.2862274328993415, 0.5926482850177996, ACCEPT, False\n",
      "of, 12.188625802377388, 0.0004808179071573432, REJECT, False\n",
      "off, 0.042311533588726295, 0.8370270746393167, ACCEPT, False\n",
      "on, 4.683889870935499, 0.03044673070170938, REJECT, False\n",
      "out, 0.5706314404525966, 0.45000810783323275, ACCEPT, False\n",
      "over, 0.17050655670197332, 0.6796620065980288, ACCEPT, False\n",
      "past, inf, 0.0874129289997089, ACCEPT, True\n",
      "through, 5.277142716848886, 0.021607178506023023, REJECT, False\n",
      "to, 2.5512975486446585, 0.11020371491785455, ACCEPT, False\n",
      "towards, 1.180977913904193, 0.2771570016277768, ACCEPT, False\n",
      "under, 0.06851825149331796, 0.7935065473138261, ACCEPT, False\n",
      "until, 0.07411849862628211, 0.785432007033074, ACCEPT, False\n",
      "up, 8.482044810734017, 0.0035866872798446963, REJECT, False\n",
      "with, 27.19458619935868, 1.8397311185480371e-07, REJECT, False\n",
      "within, 7.118759576910055, 0.007628146637715663, REJECT, False\n",
      "without, 0.00456141654351116, 0.946153204588158, ACCEPT, False\n"
     ]
    }
   ],
   "source": [
    "chi_square_test(detail_preps, not_detail_preps, total_word_count, detail_word_count, not_detail_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a03ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
