{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fdb273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re\n",
    "import re\n",
    "\n",
    "# POS\n",
    "import spacy\n",
    "\n",
    "# nltk for wordnet\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ccfb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1100f4400>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner,parser'])\n",
    "nlp.remove_pipe('ner')\n",
    "nlp.remove_pipe('parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93099db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reads in a file containing text samples, that has each sample separated by a carriage return.\n",
    "\n",
    "Args:\n",
    "    filename: location of sample file\n",
    "\n",
    "Return:\n",
    "    tagged_samples: a list of spacy `nlp` docs that contains information about each word in the sample\n",
    "'''\n",
    "def read_and_tag(filename):    \n",
    "    \n",
    "    tagged_samples = []\n",
    "    \n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        # samples are separated by line breaks\n",
    "        for sample in file:            \n",
    "            doc=nlp(sample)\n",
    "            tagged_samples.append(doc)\n",
    "        \n",
    "    return tagged_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01590ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from http://www.nltk.org/howto/wordnet.html to get *all* of a synset's hyponym/hypernyms\n",
    "hyper = lambda s: s.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f713416",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Consult wordnet for the situation of a verb or noun with respect to its station \n",
    "In the hypernym hierarchy. \n",
    "Based on current SOA, it is acceptable to simply grab the top-level (.01) synset.\n",
    "\n",
    "Args:\n",
    "    tagged_sample: a spacy doc\n",
    "\n",
    "Return:\n",
    "    specificity: a value conveying the \"specificity\" of the input, via Nelson (2020)\n",
    "'''\n",
    "\n",
    "def specificity(tagged_sample):\n",
    "    hyper_sum = 0\n",
    "    noun_and_verb_count = 0\n",
    "    for word in tagged_sample:\n",
    "        if word.pos_ == \"NOUN\" or word.pos_ == \"VERB\":\n",
    "            # if it's a verb, get the most common verb hypernym chain\n",
    "            # else, get the most common noun hypernym chain\n",
    "            pos = word.pos_\n",
    "            tag = \"n\" if pos.startswith(\"N\") else \"v\"\n",
    "            wn_lookup = word.lemma_ + \".\" + tag + \".01\"\n",
    "            try:\n",
    "                hyper_sum += len(list(wn.synset(wn_lookup).closure(hyper)))\n",
    "            except:\n",
    "                # on off chance we have a mistag, don't break down the system\n",
    "                continue\n",
    "            noun_and_verb_count +=1\n",
    "    \n",
    "    return hyper_sum / noun_and_verb_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "769a2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_counts(tagged_sample):\n",
    "    verb_count = 0\n",
    "    adj_count = 0\n",
    "    adv_count = 0\n",
    "    noun_count = 0\n",
    "    \n",
    "    for word in tagged_sample:\n",
    "        if word.pos_ == \"NOUN\":\n",
    "            noun_count +=1\n",
    "        elif word.pos_ == \"VERB\":\n",
    "            verb_count +=1\n",
    "        elif word.pos_ == \"ADJ\":\n",
    "            adj_count +=1\n",
    "        elif word.pos_ == \"ADV\":\n",
    "            adv_count +=1\n",
    "    \n",
    "    return str(adj_count) + \",\" + str(adv_count) + \",\" + str(noun_count) + \",\" + str(verb_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "120934d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_samples = read_and_tag(\"detail_samples.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dba89ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_detail_samples = read_and_tag(\"not_detail_samples.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02013354",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_attr = []\n",
    "for sample in detail_samples:\n",
    "    detail_attr.append(str(specificity(sample)) + \",\" + pos_counts(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2a6e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_detail_attr = []\n",
    "for sample in not_detail_samples:\n",
    "    not_detail_attr.append(str(specificity(sample)) + \",\" + pos_counts(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b33734c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.875,12,8,30,30'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write out detail_attr and not_detail attr to a file\n",
    "# then merge w/ existing sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925033a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
