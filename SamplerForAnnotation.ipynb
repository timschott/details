{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ea7724ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# re\n",
    "import re\n",
    "\n",
    "# data reading / cleaning\n",
    "from gut_tokenize import read_data, preprocess\n",
    "\n",
    "# ceiling \n",
    "import math \n",
    "\n",
    "# random\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "word_set = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a0ff7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This method reads and returns `num_samples` random samples of length `sample_size`\n",
    "From the inputted text. The optional advance argument lets you input a percentage\n",
    "To advance in the text (recommended: 1.5) to avoid extraneous headmatter not captured by\n",
    "the tokenization pipeline.\n",
    "\n",
    "This method is pulling from each texts as a list of strings, so, it does not limit its search to only text\n",
    "From the same paragraph, group of sentences, etc -- it will travel across those boundaries, just looking for words.\n",
    "\n",
    "When it generates the random samples, this method attempts to start a sample with a full word\n",
    "Changing something like \"...ough he told her\" to \"...he told her\". \n",
    "Thus, the samples returned could be a few characters smaller than the inputted `sample_size`. This is neglegible\n",
    "wrt the experience of reading a sample, but visually instructive.\n",
    "\n",
    "Also, the samples themselves are prefixed with elipses for clarity that they are in fact samples\n",
    "Are not standalone paragraphs, etc.\n",
    "\n",
    "Range-work adapted from https://www.geeksforgeeks.org/python-non-overlapping-random-ranges/\n",
    "\n",
    "Args:\n",
    "    text: full text of the book (list of str)\n",
    "    num_samples: how many samples to draw from a text (int)\n",
    "    sample_size: how large the samples should be, in characters (int)\n",
    "    advance: how far to advance past headmatter (float, enter as a percent i.e. 1.5 to start at the 1.5th pctle)\n",
    "\n",
    "Returns:\n",
    "    res: samples, a list of samples from the inputted `text`\n",
    "'''\n",
    "def sample_from_text(text, num_samples, sample_size, advance):\n",
    "    if text is None:\n",
    "        return\n",
    "    if num_samples < 1:\n",
    "        return\n",
    "    \n",
    "    if sample_size < 1:\n",
    "        return\n",
    "    \n",
    "    # first, advance past first 1.5% of text, just in case any head matter was retained\n",
    "    max = len(text)\n",
    "\n",
    "    floor = 0 if advance is None else math.ceil(max * (float(advance) / 100.0))\n",
    "  \n",
    "    N = num_samples\n",
    "    K = sample_size\n",
    "  \n",
    "    tot = len(text)\n",
    "    result = set()\n",
    "    for _ in range(num_samples):\n",
    "        temp = random.randint(floor, tot - sample_size)\n",
    "        \n",
    "        while any(temp >= idx and temp <= idx + sample_size for idx in result):\n",
    "            temp = random.randint(floor, tot - sample_size) \n",
    "            \n",
    "        result.add(temp)\n",
    "    result = [(idx, idx + sample_size) for idx in result]\n",
    "    \n",
    "    samples = []\n",
    "    starts = []\n",
    "    stops = []\n",
    "    for start, stop in result:\n",
    "        sample = text[start:stop]\n",
    "        # try to start with a normal word, not something like \"th in the ....\"\n",
    "        sample = sample.split(\" \")\n",
    "        if len(sample[0]) <= 2 or sample[0] not in word_set:\n",
    "            sample = sample[1:]\n",
    "        if len(sample[-1]) <= 2 or sample[-1] not in word_set:\n",
    "            sample = sample[:-1]\n",
    "        sample = ' '.join(sample)\n",
    "        # and then adding ... at the beginning at the end\n",
    "        samples.append(\"...\" + sample + \"...\")\n",
    "        starts.append(start)\n",
    "        stops.append(stop)\n",
    "    return samples, starts, stops\n",
    "\n",
    "'''\n",
    "Helper method for writing an inputted `sample` to a file.\n",
    "Args:\n",
    "    sample: text of the sample (str)\n",
    "    filename: filename, should have directory prefixed already (str)\n",
    "    \n",
    "Note that from this filename, you'll be able to reference where in the text the sample is draw from\n",
    "By grabbing the work at that index from the original text list (give or take a few words)\n",
    "\n",
    "'''\n",
    "def write_sample_to_file(sample, filename):\n",
    "    if sample is None:\n",
    "        return\n",
    "    text = open(filename, \"w\")\n",
    "    text.write(sample)\n",
    "    text.close()\n",
    "\n",
    "    \n",
    "'''\n",
    "Helper method for generating and writing samples from `texts` to files.\n",
    "Args:\n",
    "    titles: book titles for the files you are working with (string)\n",
    "    texts: book texts (str)\n",
    "    num_samples: how many samples to draw from a text (int)\n",
    "    sample_size: how large the samples should be, in characters (int)\n",
    "    advance: how far to advance past headmatter (float, enter as a percent i.e. 1.5 to start at the 1.5th pctle)\n",
    "\n",
    "Return:\n",
    "    summary string of how many samples were written and their location (hard-coded, but could be made dynamic)\n",
    "\n",
    "'''\n",
    "def write_samples_to_file(titles, texts, num_samples, sample_size, advance):\n",
    "    count = 0\n",
    "    for index, text in enumerate(texts):\n",
    "        current_book = titles[index]\n",
    "        samples, starts, stops = sample_from_text(text, num_samples, sample_size, advance)\n",
    "        for index, sample in enumerate(samples):\n",
    "            file_name = \"../Gutenberg/samples/\" + current_book.replace(\"_clean.txt\", \"\") + \"_\" + str(starts[index]) + \"_\" + str(stops[index]) + \".txt\"\n",
    "            write_sample_to_file(sample, file_name)\n",
    "            count +=1\n",
    "    \n",
    "    return \"Wrote \" + str(count) + \" samples to ../Gutenberg/samples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a875569a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wrote 364 samples to ../Gutenberg/samples.'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = \"../Gutenberg/cleaned_texts/\"\n",
    "titles = []\n",
    "texts = []\n",
    "titles, texts = read_data(directory)\n",
    "\n",
    "for index, text in enumerate(texts):\n",
    "    texts[index] = preprocess(text)\n",
    "\n",
    "write_samples_to_file(titles, texts, 13, 800, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691bb75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
