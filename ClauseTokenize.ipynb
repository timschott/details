{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762a99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading files\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# re\n",
    "import re\n",
    "\n",
    "# sentence tokenize / parse\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "# enforce max length\n",
    "en.max_length = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77efc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This method reads and returns the text of each .txt file in a directory.\n",
    "These files should be the \"cleaned\" output of the c-w gutenberg routine\n",
    "\n",
    "Args:\n",
    "    directory_name: str\n",
    "\n",
    "Returns:\n",
    "    texts: container for the inputted texts. list\n",
    "'''\n",
    "def read_data(directory_name):\n",
    "    texts = []\n",
    "    files = [f for f in listdir(directory_name) if isfile(join(directory_name, f))]\n",
    "    \n",
    "    for file in files:\n",
    "        if (\".txt\" in file):\n",
    "            with open(directory_name + file, encoding=\"utf-8\") as f:\n",
    "                #lowercase text and append\n",
    "                texts.append(f.read().lower())\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c6031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This method reads and returns the text of each .txt file in a directory.\n",
    "These inputs files should be the \"cleaned\" output of the c-w gutenberg routine\n",
    "\n",
    "- remove new lines\n",
    "- lowercase\n",
    "- advance past headmatter\n",
    "- remove chapter / vol / part numbers\n",
    "\n",
    "Args:\n",
    "    raw_text: str\n",
    "\n",
    "Returns:\n",
    "    text: rougly cleaned text\n",
    "'''\n",
    "def preprocess(raw_text):\n",
    "    \n",
    "    if raw_text is None:\n",
    "        return\n",
    "    \n",
    "    text = raw_text\n",
    "    \n",
    "    # very high level pre-processing...\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    # lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # listify, splitting on spaces\n",
    "    text = text.split(' ')\n",
    "    \n",
    "    # advance us past headmatter\n",
    "    for i in range(len(text) - 1):\n",
    "        window_val = ' '.join(text[i:i+2])\n",
    "        if (window_val == \"chapter 1\" or window_val == \"chapter i\"):\n",
    "            text = text[i+2:]\n",
    "            break\n",
    "    \n",
    "    # back to string\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    # strip all the extraneous spaces (more than 2)\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    \n",
    "    # remove volume numbers\n",
    "    text = re.sub(\"volume i{1,}|volume [0-9]{1,}|volume one|volume two|volume three\", \"\", text)\n",
    "    \n",
    "    # remove part numbers\n",
    "    text = re.sub(\"part i{1,}|volume [0-9]{1,}|part one|part two|part three\", \"\", text)\n",
    "    \n",
    "    # remove chapters\n",
    "    text = re.sub(\"chapter [a-z]+|chapter [0-9]+\", \"\", text)\n",
    "    \n",
    "    # get rid of empties\n",
    "    text = [word for word in text if word != \"\"]\n",
    "    \n",
    "    # back to string\n",
    "    text = ''.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1922473",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This method relies on the spacy parser and returns a clause-level tokenization of a given text.\n",
    "Where \"clause\" is simply text between two delimiters like commas.\n",
    "E.g. the sentence\n",
    "\"this is a test, of many things, but mostly your abilities.\" would split into:\n",
    "\n",
    "- this is a test\n",
    "- of many things\n",
    "- but mostly your abilities\n",
    "\n",
    "See https://stackoverflow.com/a/65300589 for germ of method logic\n",
    "\n",
    "Args:\n",
    "    text: document-level rep of text after being read in and roughly-cleaned\n",
    " \n",
    "Returns:\n",
    "    texts: cleaned. a list holding each clause for the text\n",
    "'''\n",
    "def clause_parse(text):\n",
    "    doc = en(text)\n",
    "    \n",
    "    # keep track of covered words\n",
    "    seen = set()\n",
    "\n",
    "    chunks = []\n",
    "    for sent in doc.sents:\n",
    "        heads = [cc for cc in sent.root.children if cc.dep_ == 'conj']\n",
    "\n",
    "        for head in heads:\n",
    "            words = [ww for ww in head.subtree]\n",
    "            for word in words:\n",
    "                seen.add(word)\n",
    "            chunk = (' '.join([ww.text for ww in words]))\n",
    "            chunks.append((head.i, chunk))\n",
    "\n",
    "        unseen = [ww for ww in sent if ww not in seen]\n",
    "        chunk = ' '.join([ww.text for ww in unseen])\n",
    "        chunks.append((sent.root.i, chunk))\n",
    "\n",
    "    chunks = sorted(chunks, key=lambda x: x[0])\n",
    "\n",
    "    cleaned = []\n",
    "\n",
    "    for ii, chunk in chunks:\n",
    "        # replace boundary char\n",
    "        chunk = chunk.replace(\",\", \"SEP\")\n",
    "        chunk = chunk.replace(\".\", \"SEP\")\n",
    "        # also replace orphan \"and\" sections\n",
    "        chunk = [c.strip() for c in chunk.split(\"SEP\") if c.strip() not in (\"\", \"and\", None)]\n",
    "        cleaned.append(chunk)\n",
    "    \n",
    "    clauses = sum(cleaned, [])\n",
    "    \n",
    "    return [clause for clause in clauses if clause != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a805d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../Gutenberg/cleaned_texts/\"\n",
    "\n",
    "texts = read_data(directory)\n",
    "\n",
    "germinal = preprocess(texts[0])\n",
    "\n",
    "germinal_clauses = clause_parse(germinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6abbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " over the open plain, beneath a starless sky as dark and thick as ink, a man walked alone along the highway from marchiennes to montsou, a straight paved road ten kilometres in length, intersecting the beetroot fields. he could not even see the black soil before him, and only felt the immense flat horizon by the gusts of march wind, squalls as strong as on the sea, and frozen from sweeping leagues of marsh and naked earth. no tree could be seen against the sky, and the road unrolled as straight as a pier in the midst of the blinding spray of darkness. \n",
      "============\n",
      "over the open plain\n",
      "beneath a starless sky as dark and thick as ink\n",
      "a man walked alone along the highway from marchiennes to montsou\n",
      "a straight paved road ten kilometres in length\n",
      "intersecting the beetroot fields\n",
      "he could not even see the black soil before him\n",
      "only felt the immense flat horizon by the gusts of march wind\n",
      "squalls as strong as on the sea\n",
      "and frozen from sweeping leagues of marsh and naked earth\n",
      "no tree could be seen against the sky\n",
      "the road unrolled as straight as a pier in the midst of the blinding spray of darkness\n"
     ]
    }
   ],
   "source": [
    "print(germinal[0: 558])\n",
    "\n",
    "print('============')\n",
    "\n",
    "clause_count = 0\n",
    "for c in germinal_clauses:\n",
    "    print (c)\n",
    "    clause_count += 1\n",
    "    if clause_count == 11:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "715df9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_and_modifiers(clauses):\n",
    "    \n",
    "    # obj: vanilla object\n",
    "    # pobj: object of a pr\n",
    "    # iobj: indirect obj\n",
    "    # pobj: prep. obj\n",
    "    # npadvmod: noun phrase as adverbial modifier (common for measurements; 20 years old)\n",
    "    # nsubj: noun subject\n",
    "    # nsubjpass: passive nominal subject\n",
    "    # acomp: adjectival complement\n",
    "    \n",
    "    np_labels = ['compound', 'obj','dobj','iobj','pobj','npadvmod','nsubj','nsubjpass']\n",
    "    \n",
    "    # modifiers ... acl, amod, nummod, nn, advmod\n",
    "    \n",
    "    detail_dict = {}\n",
    "    count = 0\n",
    "    for clause in clauses:\n",
    "        print(\"==============\")\n",
    "        doc = en(clause)\n",
    "        for word in doc:\n",
    "            # if word.dep_ in np_labels \n",
    "            if word.pos_ == \"NOUN\" or word.pos_ == \"VERB\":\n",
    "                detail_chunks = [] \n",
    "                size = sum(1 for dummy in word.subtree)\n",
    "                if size > 1:\n",
    "                    detail_chunk = []\n",
    "                    for descendant in word.subtree:\n",
    "                        detail_chunk.append(descendant.text)\n",
    "                    detail_chunks.append(detail_chunk)\n",
    "                if detail_chunks:\n",
    "                    print(detail_chunks)\n",
    "  #      detail_dict[count] = \"|\".join(sum(detail_chunks, []))\n",
    "  #      count += 1\n",
    "            \n",
    "  #  print(detail_dict)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a58acd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "[['the', 'open', 'plain']]\n",
      "==============\n",
      "[['a', 'starless', 'sky']]\n",
      "==============\n",
      "[['a', 'man']]\n",
      "[['a', 'man', 'walked', 'alone', 'along', 'the', 'highway', 'from', 'marchiennes', 'to', 'montsou']]\n",
      "[['the', 'highway']]\n",
      "[['to', 'montsou']]\n",
      "==============\n",
      "[['a', 'straight', 'paved', 'road', 'ten', 'kilometres', 'in', 'length']]\n",
      "[['ten', 'kilometres', 'in', 'length']]\n",
      "==============\n",
      "[['intersecting', 'the', 'beetroot', 'fields']]\n",
      "[['the', 'beetroot', 'fields']]\n",
      "==============\n",
      "[['he', 'could', 'not', 'even', 'see', 'the', 'black', 'soil', 'before', 'him']]\n",
      "[['the', 'black', 'soil', 'before', 'him']]\n",
      "==============\n",
      "[['only', 'felt', 'the', 'immense', 'flat', 'horizon', 'by', 'the', 'gusts', 'of', 'march', 'wind']]\n",
      "[['the', 'immense', 'flat', 'horizon', 'by', 'the', 'gusts', 'of', 'march', 'wind']]\n",
      "[['the', 'gusts', 'of', 'march', 'wind']]\n",
      "[['march', 'wind']]\n",
      "==============\n",
      "[['squalls', 'as', 'strong', 'as', 'on', 'the', 'sea']]\n",
      "[['the', 'sea']]\n",
      "==============\n",
      "[['and', 'frozen', 'from', 'sweeping', 'leagues', 'of', 'marsh', 'and', 'naked', 'earth']]\n",
      "[['sweeping', 'leagues', 'of', 'marsh', 'and', 'naked', 'earth']]\n",
      "[['marsh', 'and', 'naked']]\n",
      "[['marsh', 'and', 'naked', 'earth']]\n",
      "==============\n",
      "[['no', 'tree']]\n",
      "[['no', 'tree', 'could', 'be', 'seen', 'against', 'the', 'sky']]\n",
      "[['the', 'sky']]\n",
      "==============\n",
      "[['the', 'road', 'unrolled', 'as', 'straight', 'as', 'a', 'pier', 'in', 'the', 'midst', 'of', 'the', 'blinding', 'spray', 'of', 'darkness']]\n",
      "[['a', 'pier', 'in', 'the', 'midst', 'of', 'the', 'blinding', 'spray', 'of', 'darkness']]\n",
      "[['the', 'midst', 'of', 'the', 'blinding', 'spray', 'of', 'darkness']]\n",
      "[['the', 'blinding', 'spray', 'of', 'darkness']]\n"
     ]
    }
   ],
   "source": [
    "nouns_and_modifiers(germinal_clauses[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda8782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
